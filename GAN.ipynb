{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/williamblair/williamblair/miniconda/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "(3200, 2246)\n",
      "(?, 2205)\n",
      "(?, 60)\n",
      "(?, 5)\n",
      "(?, 40, 56, 1)\n",
      "WARNING:tensorflow:From /Users/williamblair/williamblair/miniconda/envs/tensorflow/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /var/folders/6j/tgb081b50n99wmbtnv2pqkx00000gn/T/ipykernel_37314/540058988.py:164: The name tf.keras.optimizers.Adam is deprecated. Please use tf.keras.optimizers.legacy.Adam instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['discriminator_1/dense_6/kernel:0', 'discriminator_1/dense_6/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['generator/dense_1/kernel:0', 'generator/dense_1/bias:0', 'generator/dense_2/kernel:0', 'generator/dense_2/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 195\u001b[0m\n\u001b[1;32m    192\u001b[0m g_train_opt \u001b[39m=\u001b[39m g_optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(g_gradients, g_vars))\n\u001b[1;32m    194\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m--> 195\u001b[0m     \u001b[39mfor\u001b[39;00m batch_i, (real_image_batch, label_batch) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataset):\n\u001b[1;32m    196\u001b[0m         \u001b[39m# generate noise\u001b[39;00m\n\u001b[1;32m    197\u001b[0m         batch_noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, size\u001b[39m=\u001b[39m(batch_size, noise_size))\n\u001b[1;32m    199\u001b[0m         \u001b[39m# Train the discriminator\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def one_hot(y_):\n",
    "    # Function to encode output labels from number indexes\n",
    "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    y_ = y_.reshape(len(y_))\n",
    "    y_ = [int(x) for x in y_]\n",
    "    n_values = np.max(y_) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]\n",
    "\n",
    "\n",
    "def get_generator(noise_img, n_units, out_dim, reuse=False, alpha=0.01):\n",
    "    \"\"\"\n",
    "    generator\n",
    "    noise_img: input\n",
    "    n_units: hidden node number\n",
    "    out_dim: output size, here is 32*32=784\n",
    "    alpha: leaky ReLU coefficient\n",
    "    \"\"\"\n",
    "    global n_class\n",
    "    momentum = 0.9\n",
    "\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "        # Deconvolutional\n",
    "        noise_img = tf.layers.dense(noise_img, units=140 * 64)\n",
    "\n",
    "        h0 = tf.reshape(noise_img, [-1, 10, 14, 64])\n",
    "\n",
    "        h0 = tf.nn.relu(tf.contrib.layers.batch_norm(h0, decay=momentum))\n",
    "\n",
    "        h3 = tf.layers.conv2d_transpose(h0, kernel_size=5, filters=32, strides=2, padding='same')\n",
    "        h3 = tf.nn.relu(tf.contrib.layers.batch_norm(h3, decay=momentum))\n",
    "\n",
    "        h4 = tf.layers.conv2d_transpose(h3, kernel_size=5, filters=1, strides=2, padding='same',\n",
    "                                        name='g')\n",
    "\n",
    "        #  logits & outputs\n",
    "        logits = tf.reshape(h4, [-1, 40 * 56])\n",
    "        outputs = tf.tanh(logits)\n",
    "        mid = tf.sigmoid(tf.layers.dense(logits, units=20 * 20))\n",
    "        pred = tf.layers.dense(mid, units=n_class)\n",
    "\n",
    "        return logits, outputs, pred\n",
    "\n",
    "\n",
    "def get_discriminator(img, n_units, reuse=False, alpha=0.01, cond=None):\n",
    "    momentum = 0.9\n",
    "    # Select the EEG features from the input conditional featrues\n",
    "    # the last 40 dimensions are EEG\n",
    "    con = cond[:, noise_size - 40:noise_size]\n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "        # CNN\n",
    "        z_image = tf.reshape(img, [-1, 40, 56, 1])\n",
    "        h0 = lrelu(tf.layers.conv2d(z_image, kernel_size=5, filters=32, strides=2, padding='same'))\n",
    "        h0 = lrelu(tf.contrib.layers.batch_norm(h0, decay=momentum))\n",
    "\n",
    "        h1 = lrelu(tf.layers.conv2d(h0, kernel_size=5, filters=64, strides=2, padding='same'))\n",
    "        h1 = lrelu(tf.contrib.layers.batch_norm(h1, decay=momentum))\n",
    "\n",
    "        hidden1 = tf.contrib.layers.flatten(h1)\n",
    "\n",
    "        hidden1 = tf.concat([hidden1, con], axis=1)  # add the EEG features as conditional information.\n",
    "\n",
    "        # logits & outputs, discriminative True/False\n",
    "        logits = tf.layers.dense(hidden1, 1)\n",
    "        outputs = logits  # tf.tanh(logits)  # normalize the generated image\n",
    "\n",
    "        # classify 5 categories\n",
    "        outputs_2 = tf.layers.dense(hidden1, n_class)\n",
    "\n",
    "        return logits, outputs, outputs_2\n",
    "\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    correct_prediction = tf.equal(tf.argmax(v_xs, 1), tf.argmax(v_ys, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def lrelu(x, leak=0.2):\n",
    "    return tf.maximum(x, leak * x)\n",
    "\n",
    "\n",
    "img_size = 40 * 56\n",
    "noise_size = 60\n",
    "n_class = 5\n",
    "\n",
    "\"\"\"\n",
    "load the shuffled data, [3200, 2281], 2286 = 40 + 2240 + 1\n",
    "In which, 40 is EEG features, 2240 = 40*56 is the image, 1 is the label\n",
    "\"\"\"\n",
    "data = pickle.load(open('shape_EEG_feature.pkl', 'rb'))\n",
    "\n",
    "label = data[:, -1]\n",
    "label.shape = [3200, 1]\n",
    "# print(np.sum(label), label.shape, np.max(data[0, 40:-1]), np.min(data[0, 40:-1]))\n",
    "\n",
    "label = one_hot(label)\n",
    "\n",
    "# make the D_2 label\n",
    "g_units = 200\n",
    "d_units = g_units\n",
    "alpha = 0.01\n",
    "# label smoothing\n",
    "smooth = 0.1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "real_img = tf.placeholder(tf.float32, [None, img_size], name='real_img')\n",
    "noise_img = tf.placeholder(tf.float32, [None, noise_size], name='noise_img')\n",
    "ground_truth = tf.placeholder(tf.float32, shape=[None, n_class], name='ground_truth')\n",
    "\n",
    "# generator\n",
    "g_logits, g_outputs, pred = get_generator(noise_img, g_units, img_size)\n",
    "# discriminator\n",
    "d_logits_real, d_outputs_real, real_category_pred = get_discriminator(real_img, d_units, cond=noise_img)\n",
    "d_logits_fake, d_outputs_fake, fake_category_pred = get_discriminator(g_outputs, d_units, cond=noise_img, reuse=True)\n",
    "\n",
    "# ACC\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(ground_truth, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# # discriminatorloss # cross-entropy\n",
    "d_loss_real = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_logits_real)) * (1 - smooth))\n",
    "d_loss_fake = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_logits_fake)))\n",
    "\n",
    "# reduce_mean\n",
    "d_loss_rf = tf.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "d_loss_category_real = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=real_category_pred, labels=ground_truth))\n",
    "d_loss_category_fake = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_category_pred, labels=ground_truth))\n",
    "d_loss_category = tf.add(0.8 * d_loss_category_real, d_loss_category_fake)\n",
    "d_loss = d_loss_rf + d_loss_category_real\n",
    "\n",
    "# classifier loss\n",
    "c_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=ground_truth))\n",
    "# calculate the inception classification accuracy, evaluating is the generated image is correct?\n",
    "IC_fake = compute_accuracy(ground_truth, fake_category_pred)\n",
    "IC_real = compute_accuracy(ground_truth, real_category_pred)\n",
    "\n",
    "# generator loss\n",
    "lambda_ = 0.01\n",
    "batch_size = 80\n",
    "\n",
    "g_loss = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_logits_fake)) * (1 - smooth))\n",
    "\n",
    "# regularization of generated fake image with the real image:\n",
    "g_regular = tf.losses.mean_squared_error(labels=real_img, predictions=g_outputs)\n",
    "g_loss = g_loss + d_loss_category_fake + lambda_ * g_regular\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "# generator tensor\n",
    "g_vars = [var for var in train_vars if var.name.startswith(\"generator\")]\n",
    "# discriminator tensor\n",
    "d_vars = [var for var in train_vars if var.name.startswith(\"discriminator\")]\n",
    "\n",
    "# optimizer\n",
    "learning_rate = 0.0002  # 0.0002\n",
    "d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=0.5).minimize(d_loss, var_list=d_vars)\n",
    "g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=0.5).minimize(g_loss, var_list=g_vars)\n",
    "c_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(c_loss, var_list=g_vars)\n",
    "\n",
    "# batch_size\n",
    "epochs = 500\n",
    "n_sample = batch_size\n",
    "n_batch = int(data.shape[0] / batch_size)\n",
    "# n_batch = 1\n",
    "\n",
    "samples = []\n",
    "losses = []\n",
    "\n",
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for h in range(n_batch):\n",
    "        # print(\"this is number \", h)\n",
    "        z_batch = data[batch_size * h:batch_size * (h + 1), 0:40]\n",
    "        real_image_batch = data[batch_size * h:batch_size * (h + 1), 40:-1]\n",
    "        label_batch = label[batch_size * h:batch_size * (h + 1)]\n",
    "        label_batch = label_batch.astype(float)\n",
    "\n",
    "        # batch_images = batch[0].reshape((batch_size, 784))\n",
    "        real_image_batch = real_image_batch * 2 - 1\n",
    "        z_batch = z_batch * 2 - 1\n",
    "\n",
    "        batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size))\n",
    "        batch_noise = np.hstack((batch_noise[:, :20], z_batch[:, :40]))  # 130 noise + 10 EEG channels\n",
    "        # batch_noise = z_batch[:, :40]\n",
    "\n",
    "        # Run optimizers\n",
    "        _ = sess.run(d_train_opt,\n",
    "                     feed_dict={real_img: real_image_batch, noise_img: batch_noise, ground_truth: label_batch})\n",
    "        for i in range(2):\n",
    "            _ = sess.run(g_train_opt,\n",
    "                         feed_dict={real_img: real_image_batch, noise_img: batch_noise, ground_truth: label_batch})\n",
    "\n",
    "    if e % 50 == 0 and e != 0:\n",
    "        # discriminator loss\n",
    "        train_loss_d, train_loss_d_rf, train_loss_d_category = sess.run([d_loss, d_loss_rf, d_loss_category],\n",
    "                                                                        feed_dict={real_img: real_image_batch,\n",
    "                                                                                   noise_img: batch_noise,\n",
    "                                                                                   ground_truth: label_batch})\n",
    "\n",
    "        # generator loss\n",
    "        train_loss_g, train_loss_c, acc, g_regular_ = sess.run([g_loss, c_loss, accuracy, g_regular],\n",
    "                                                               feed_dict={real_img: real_image_batch,\n",
    "                                                                          noise_img: batch_noise,\n",
    "                                                                          ground_truth: label_batch})\n",
    "        # IC score\n",
    "        ic_real_, ic_fake_ = sess.run([IC_real, IC_fake],\n",
    "                                      feed_dict={real_img: real_image_batch, noise_img: batch_noise,\n",
    "                                                 ground_truth: label_batch})\n",
    "        print(\"Epoch {}/{}\".format(e + 1, epochs),\n",
    "              \"D Loss: {:.4f}(r/f: {:.4f} + category: {:.4f})\".format(train_loss_d, train_loss_d_rf,\n",
    "                                                                      train_loss_d_category),\n",
    "              \"G Loss: {:.4f}, RMSE:{:.4f} , C loss{:.4f}, acc, {:.4f}\".format(train_loss_g,\n",
    "                                                                    lambda_ * g_regular_, train_loss_c, acc),\n",
    "              'IC real.{:.4f}, fake: {:.4f}'.format(ic_real_, ic_fake_))\n",
    "        losses.append((train_loss_d, train_loss_d_rf, train_loss_d_category, train_loss_g), )\n",
    "\n",
    "        \"\"\"test  \"\"\"\n",
    "        h = n_batch - 3\n",
    "        z_batch_ = data[batch_size * h:batch_size * (h + 1), :40]  # the last batch worked as testingsample\n",
    "        true_label = data[batch_size * h:batch_size * (h + 1), -1]\n",
    "        real_ = data[batch_size * h:batch_size * (h + 1), 40:-1]\n",
    "        \"\"\"half noise half EEG\"\"\"\n",
    "        sample_noise = np.random.uniform(-1, 1, size=(n_sample, noise_size))\n",
    "        sample_noise = np.hstack((sample_noise[:, :20], z_batch_[:, :40]))  # 130 noise + 10 EEG channels\n",
    "\n",
    "        _, gen_samples, pred_ = sess.run(get_generator(noise_img, g_units, img_size, reuse=True),\n",
    "                                         feed_dict={real_img: real_image_batch, noise_img: sample_noise, })\n",
    "\n",
    "        # fig = plt.figure(figsize=(30, 6))\n",
    "        # print 'true label,', true_label[1:10]\n",
    "        # no_pic = 12\n",
    "        # for i in range(1, no_pic+1):  # 8 samples including 5 categories\n",
    "        #     generated_image = gen_samples[i].reshape([40, 56])\n",
    "        #     real_image = real_[i].reshape([40, 56])\n",
    "        #     fig.add_subplot(1, no_pic, i)\n",
    "        #     plt.axis('off')\n",
    "        #     plt.imshow(generated_image, cmap='gray_r')\n",
    "        # plt.savefig('generated_images/step'+str(e)+'.png', format='png', bbox_inches='tight')\n",
    "        # pickle.dump(gen_samples, open('GAN_1.pk', 'wb'))\n",
    "\n",
    "        \"\"\"Save all the images\"\"\"\n",
    "        for j in range(10):\n",
    "            im = gen_samples[j].reshape([40, 56])\n",
    "            Image.fromarray(im, mode='L').save('generated_images/' + str(e) + '_' + str(j) + '.jpg')\n",
    "\n",
    "        print('image saved', true_label[0:20])\n",
    "        # plt.imshow(im, cmap='gray_r')\n",
    "        # plt.savefig('generated_images/images/step' + str(j) + '.png', format='png', bbox_inches='tight')\n",
    "\n",
    "        # plt.show()\n",
    "        # samples.append(gen_samples)\n",
    "        # saver.save(sess, './checkpoints/generator.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
